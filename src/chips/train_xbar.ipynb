{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rebal\\capstone-project\\capstone\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import gzip\n",
    "from scipy.sparse import coo_matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SimpleConv\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DEHNNLayer(nn.Module):\n",
    "    def __init__(self, node_in_features, edge_in_features, vn_features):\n",
    "        super(DEHNNLayer, self).__init__()\n",
    "        self.node_mlp1 = nn.Sequential(nn.Linear(edge_in_features, edge_in_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(edge_in_features, edge_in_features))\n",
    "        \n",
    "        self.edge_mlp2 = nn.Sequential(nn.Linear(node_in_features, node_in_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(node_in_features, node_in_features))\n",
    "        \n",
    "        self.edge_mlp3 = nn.Sequential(nn.Linear(2 * node_in_features, 2 * node_in_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(2 * node_in_features, 2 * node_in_features))\n",
    "\n",
    "        self.node_to_virtual_mlp = nn.Sequential(nn.Linear(node_in_features, vn_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(vn_features, vn_features))\n",
    "        \n",
    "        self.virtual_to_higher_virtual_mlp = nn.Sequential(nn.Linear(vn_features, vn_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(vn_features, vn_features))\n",
    "        \n",
    "        self.higher_virtual_to_virtual_mlp = nn.Sequential(nn.Linear(vn_features, vn_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(vn_features, vn_features))\n",
    "        \n",
    "        self.virtual_to_node_mlp = nn.Sequential(nn.Linear(vn_features, vn_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(vn_features, edge_in_features))\n",
    "\n",
    "        # Learnable defaults for missing driver or sink\n",
    "        self.default_driver = nn.Parameter(torch.zeros(node_in_features))\n",
    "        self.default_sink_agg = nn.Parameter(torch.zeros(node_in_features))\n",
    "        self.default_edge_agg = nn.Parameter(torch.zeros(edge_in_features))\n",
    "\n",
    "    def forward(self, node_features, edge_features, vn_features, super_vn_features, hypergraph):\n",
    "        # Node update\n",
    "        updated_node_features = {}\n",
    "        for node in range(hypergraph.num_nodes):\n",
    "            incident_edges = hypergraph.get_incident_edges(node)\n",
    "            if incident_edges:\n",
    "                agg_features = torch.sum(torch.stack([self.node_mlp1(edge_features[edge]) for edge in incident_edges]), dim=0)\n",
    "            else:\n",
    "                agg_features = self.default_edge_agg  # Fallback for isolated nodes\n",
    "            updated_node_features[node] = agg_features\n",
    "\n",
    "        # Edge update\n",
    "        updated_edge_features = {}\n",
    "        for edge in range(hypergraph.num_edges):\n",
    "            driver, sinks = hypergraph.get_driver_and_sinks(edge)\n",
    "\n",
    "            # Handle missing driver\n",
    "            driver_feature = node_features[driver] if driver is not None else self.default_driver\n",
    "\n",
    "            # Handle missing sinks\n",
    "            if sinks:\n",
    "                sink_agg = torch.sum(torch.stack([self.edge_mlp2(node_features[sink]) for sink in sinks]), dim=0)\n",
    "            else:\n",
    "                sink_agg = self.default_sink_agg\n",
    "\n",
    "            # Concatenate and update\n",
    "            concatenated = torch.cat([driver_feature, sink_agg])\n",
    "            updated_edge_features[edge] = self.edge_mlp3(concatenated)\n",
    "        \n",
    "        updated_vn_features = {}\n",
    "        for virtual_node in range(hypergraph.num_vn):\n",
    "            assigned_nodes = hypergraph.get_nodes_from_vn(virtual_node)\n",
    "            agg_features = torch.sum(torch.stack([self.node_to_virtual_mlp(node_features[node]) for node in assigned_nodes]), dim=0)\n",
    "            agg_features += self.higher_virtual_to_virtual_mlp(super_vn_features)\n",
    "            updated_vn_features[virtual_node] = agg_features\n",
    "\n",
    "        updated_super_vn_features = torch.sum(\n",
    "            torch.stack([self.virtual_to_higher_virtual_mlp(vn_features[vn]) for vn in range(hypergraph.num_vn)]), dim=0\n",
    "        )\n",
    "\n",
    "        for node in range(hypergraph.num_nodes):\n",
    "            virtual_node = hypergraph.get_vn_from_node(node)\n",
    "            propagated_feature = self.virtual_to_node_mlp(vn_features[virtual_node])\n",
    "            updated_node_features[node] += propagated_feature  # Add propagated feature to node\n",
    "\n",
    "        return updated_node_features, updated_edge_features, updated_vn_features, updated_super_vn_features\n",
    "\n",
    "\n",
    "class DEHNN(nn.Module):\n",
    "    def __init__(self, num_layers, node_in_features, edge_in_features):\n",
    "        super(DEHNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Create multiple layers for DEHNN\n",
    "        vn_in_features = node_in_features\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(DEHNNLayer(node_in_features, edge_in_features, vn_in_features))\n",
    "            node_in_features, edge_in_features = edge_in_features, node_in_features\n",
    "            edge_in_features *= 2\n",
    "\n",
    "        edge_in_features  = int(edge_in_features / 2)\n",
    "        self.output_layer = nn.Linear(node_in_features, 1)\n",
    "\n",
    "    def forward(self, node_features, edge_features, vn_features, super_vn_features, hypergraph):\n",
    "        # Pass through each layer\n",
    "        for layer in self.layers:\n",
    "            node_features, edge_features, vn_features, super_vn_features = layer(node_features, edge_features, vn_features, super_vn_features, hypergraph)\n",
    "        \n",
    "        # Output prediction for nodes\n",
    "        final_node_features = torch.stack([node_features[node] for node in range(hypergraph.num_nodes)], dim=0)\n",
    "        output = self.output_layer(final_node_features)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Example hypergraph representation class (simplified)\n",
    "class Hypergraph:\n",
    "    def __init__(self, num_nodes, num_edges, num_vn, driver_sink_map, node_to_virtual, virtual_to_node, incidence_matrix):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_edges = num_edges\n",
    "        self.num_vn = num_vn\n",
    "        self.driver_sink_map = driver_sink_map\n",
    "        self.node_to_virtual = node_to_virtual\n",
    "        self.virtual_to_node = virtual_to_node\n",
    "        self.incidence_matrix = incidence_matrix\n",
    "\n",
    "    def get_incident_edges(self, node):\n",
    "        return [edge for edge in range(self.num_edges) if node in self.driver_sink_map[edge][1] or node == self.driver_sink_map[edge][0]]\n",
    "\n",
    "    def get_driver_and_sinks(self, edge):\n",
    "        return self.driver_sink_map[edge]\n",
    "    \n",
    "    def get_vn_from_node(self, node):\n",
    "        return self.node_to_virtual[node]\n",
    "    \n",
    "    def get_nodes_from_vn(self, vn):\n",
    "        return self.virtual_to_node[vn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "clean_data_dir = '../../data/chips/clean_data/'\n",
    "\n",
    "with open(clean_data_dir + '1.driver_sink_map.pkl', 'rb') as f:\n",
    "    driver_sink_map = pickle.load(f)\n",
    "\n",
    "with open(clean_data_dir + '1.node_features.pkl', 'rb') as f:\n",
    "    node_features = pickle.load(f)\n",
    "\n",
    "with open(clean_data_dir + '1.net_features.pkl', 'rb') as f:\n",
    "    edge_features = pickle.load(f)\n",
    "\n",
    "with open(clean_data_dir + '1.congestion.pkl', 'rb') as f:\n",
    "    congestion = pickle.load(f)\n",
    "\n",
    "partition = np.load(clean_data_dir + '1.partition.npy')\n",
    "conn = np.load('../../data/chips/NCSU-DigIC-GraphData-2023-07-25/xbar/1/xbar_connectivity.npz')\n",
    "\n",
    "incidence_matrix = torch.sparse_coo_tensor(torch.tensor(np.array([conn['row'], conn['col']])), torch.ones(conn['data'].shape), dtype=torch.float).to(device)\n",
    "\n",
    "node_features = torch.tensor(np.array(list(node_features.values())), dtype=torch.float).to(device)\n",
    "edge_features = torch.tensor(np.array(list(edge_features.values())), dtype=torch.float).to(device)\n",
    "\n",
    "num_nodes, num_node_features = node_features.shape\n",
    "num_edges, num_edge_features = edge_features.shape\n",
    "\n",
    "node_to_virtual = {i: p for i, p in enumerate(partition)}\n",
    "virtual_to_node = defaultdict(list)\n",
    "for i, p in enumerate(partition):\n",
    "    virtual_to_node[p].append(i)\n",
    "\n",
    "num_vn = len(virtual_to_node)\n",
    "vn_features = torch.zeros((num_vn, num_node_features), dtype=torch.float).to(device)\n",
    "super_vn_features = torch.zeros(num_node_features, dtype=torch.float).to(device)\n",
    "\n",
    "nodes = list(range(len(node_features)))\n",
    "edges = list(range(len(edge_features)))\n",
    "hypergraph = Hypergraph(num_nodes, num_edges, num_vn, driver_sink_map, node_to_virtual, virtual_to_node, incidence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidence_matrix.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0796]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]._modules['node_mlp1'][0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8652]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]._modules['node_mlp1'](torch.tensor([[42]], dtype=torch.float).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0]._modules['node_mlp1'](torch.tensor([[0.8652]], dtype=torch.float).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.],\n",
       "        [42.],\n",
       "        [ 1.],\n",
       "        ...,\n",
       "        [33.],\n",
       "        [33.],\n",
       "        [14.]], device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 78.7692\n"
     ]
    }
   ],
   "source": [
    "# Initialize DE-HNN model\n",
    "model = DEHNN(num_layers=4, node_in_features=num_node_features, edge_in_features=num_edge_features).to(device)\n",
    "epochs = 1\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Training Loop (example)\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(node_features, edge_features, vn_features, super_vn_features, hypergraph)\n",
    "    output = output[:,0]\n",
    "    # print(output)\n",
    "    \n",
    "    # Dummy target for illustration (binary labels for each node: 0 for not congested, 1 for congested)\n",
    "    target = torch.tensor(list(congestion.values())).to(device)\n",
    "    \n",
    "    # print(target)\n",
    "    # Compute loss\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): DEHNNLayer(\n",
       "    (node_mlp1): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=1, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1, out_features=1, bias=True)\n",
       "    )\n",
       "    (edge_mlp2): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (edge_mlp3): Sequential(\n",
       "      (0): Linear(in_features=28, out_features=28, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=28, out_features=28, bias=True)\n",
       "    )\n",
       "    (node_to_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (virtual_to_higher_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (higher_virtual_to_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (virtual_to_node_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): DEHNNLayer(\n",
       "    (node_mlp1): Sequential(\n",
       "      (0): Linear(in_features=28, out_features=28, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=28, out_features=28, bias=True)\n",
       "    )\n",
       "    (edge_mlp2): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=1, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1, out_features=1, bias=True)\n",
       "    )\n",
       "    (edge_mlp3): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2, out_features=2, bias=True)\n",
       "    )\n",
       "    (node_to_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (virtual_to_higher_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (higher_virtual_to_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (virtual_to_node_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=28, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (2): DEHNNLayer(\n",
       "    (node_mlp1): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2, out_features=2, bias=True)\n",
       "    )\n",
       "    (edge_mlp2): Sequential(\n",
       "      (0): Linear(in_features=28, out_features=28, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=28, out_features=28, bias=True)\n",
       "    )\n",
       "    (edge_mlp3): Sequential(\n",
       "      (0): Linear(in_features=56, out_features=56, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=56, out_features=56, bias=True)\n",
       "    )\n",
       "    (node_to_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=28, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (virtual_to_higher_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (higher_virtual_to_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (virtual_to_node_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (3): DEHNNLayer(\n",
       "    (node_mlp1): Sequential(\n",
       "      (0): Linear(in_features=56, out_features=56, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=56, out_features=56, bias=True)\n",
       "    )\n",
       "    (edge_mlp2): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2, out_features=2, bias=True)\n",
       "    )\n",
       "    (edge_mlp3): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (node_to_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (virtual_to_higher_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (higher_virtual_to_virtual_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=14, bias=True)\n",
       "    )\n",
       "    (virtual_to_node_mlp): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=56, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 396, 1, 3555]\n",
      "Accuracy: 0.8995445344129555\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "out = output.detach().cpu().numpy()\n",
    "real = target.detach().cpu().numpy()\n",
    "\n",
    "lst = [0, 0, 0, 0]\n",
    "for i, j in zip(out, real):\n",
    "    if i >= 0.9 and j >= 0.9:\n",
    "        lst[0] += 1\n",
    "    elif i < 0.9 and j >= 0.9:\n",
    "        lst[1] += 1\n",
    "    elif i >= 0.9 and j < 0.9:\n",
    "        lst[2] += 1\n",
    "    else:\n",
    "        lst[3] += 1\n",
    "total = sum(lst)\n",
    "print(lst)\n",
    "print(f'Accuracy: {(lst[0] + lst[3]) / total}')\n",
    "print(f'Precision: {lst[0] / (lst[0] + lst[1])}')\n",
    "print(f'Accuracy: {lst[0] / (lst[0] + lst[2])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20099005, 0.20232299, 0.17674008, ..., 0.07204804, 0.02181804,\n",
       "       0.00367373], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83333333, 0.72222222, 0.83333333, ..., 0.57142857, 0.69444444,\n",
       "       0.6969697 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast train\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "clean_data_dir = '../../data/chips/clean_data/'\n",
    "\n",
    "with open(clean_data_dir + '1.driver_sink_map.pkl', 'rb') as f:\n",
    "    driver_sink_map = pickle.load(f)\n",
    "\n",
    "with open(clean_data_dir + '1.node_features.pkl', 'rb') as f:\n",
    "    node_features = pickle.load(f)\n",
    "\n",
    "with open(clean_data_dir + '1.net_features.pkl', 'rb') as f:\n",
    "    edge_features = pickle.load(f)\n",
    "\n",
    "with open(clean_data_dir + '1.congestion.pkl', 'rb') as f:\n",
    "    congestion = pickle.load(f)\n",
    "\n",
    "partition = np.load(clean_data_dir + '1.partition.npy')\n",
    "conn = np.load(clean_data_dir + '1.connectivity.npz')\n",
    "\n",
    "incidence_matrix = torch.sparse_coo_tensor(torch.tensor(np.array([conn['row'], conn['col']])), torch.ones(conn['dirs'].shape), dtype=torch.float).to(device)\n",
    "\n",
    "idx = conn['dirs'] == 1\n",
    "driver_matrix = torch.sparse_coo_tensor(torch.tensor(np.array([conn['col'][idx], conn['row'][idx]])), torch.ones(conn['dirs'][idx].shape), dtype=torch.float).to(device)\n",
    "\n",
    "idx = conn['dirs'] == 0\n",
    "sink_matrix = torch.sparse_coo_tensor(torch.tensor(np.array([conn['col'][idx], conn['row'][idx]])), torch.ones(conn['dirs'][idx].shape), dtype=torch.float).to(device)\n",
    "\n",
    "node_features = torch.tensor(np.array(list(node_features.values())), dtype=torch.float).to(device)\n",
    "edge_features = torch.tensor(np.array(list(edge_features.values())), dtype=torch.float).to(device)\n",
    "\n",
    "num_nodes, num_node_features = node_features.shape\n",
    "num_edges, num_edge_features = edge_features.shape\n",
    "\n",
    "node_to_virtual = {i: p for i, p in enumerate(partition)}\n",
    "virtual_to_node = defaultdict(list)\n",
    "for i, p in enumerate(partition):\n",
    "    virtual_to_node[p].append(i)\n",
    "\n",
    "num_vn = len(virtual_to_node)\n",
    "vn_features = torch.zeros((num_vn, num_node_features), dtype=torch.float).to(device)\n",
    "super_vn_features = torch.zeros(num_node_features, dtype=torch.float).to(device)\n",
    "\n",
    "vn_rows = []\n",
    "vn_cols = []\n",
    "\n",
    "for k, v in virtual_to_node.items():\n",
    "    for n in v:\n",
    "        vn_rows.append(k)\n",
    "        vn_cols.append(n)\n",
    "\n",
    "vn_matrix = torch.sparse_coo_tensor(torch.tensor(np.array([vn_rows, vn_cols])), torch.ones(len(vn_rows)), dtype=torch.float).to(device)\n",
    "\n",
    "nodes = list(range(len(node_features)))\n",
    "edges = list(range(len(edge_features)))\n",
    "hypergraph = Hypergraph(num_nodes, num_edges, num_vn, driver_sink_map, node_to_virtual, virtual_to_node, incidence_matrix, driver_matrix, sink_matrix, vn_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
