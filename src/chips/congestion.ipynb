{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rebal\\capstone-project\\capstone\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DEHNNLayer(nn.Module):\n",
    "    def __init__(self, node_in_features, edge_in_features, vn_features, hidden_features):\n",
    "        super(DEHNNLayer, self).__init__()\n",
    "        self.node_mlp1 = nn.Sequential(nn.Linear(edge_in_features, hidden_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_features, edge_in_features))\n",
    "        \n",
    "        self.edge_mlp2 = nn.Sequential(nn.Linear(node_in_features, hidden_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_features, node_in_features))\n",
    "        \n",
    "        self.edge_mlp3 = nn.Sequential(nn.Linear(2 * node_in_features, hidden_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_features, 2 * node_in_features))\n",
    "\n",
    "        self.node_to_virtual_mlp = nn.Sequential(nn.Linear(node_in_features, hidden_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_features, vn_features))\n",
    "        \n",
    "        self.virtual_to_higher_virtual_mlp = nn.Sequential(nn.Linear(vn_features, hidden_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_features, vn_features))\n",
    "        \n",
    "        self.higher_virtual_to_virtual_mlp = nn.Sequential(nn.Linear(vn_features, hidden_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_features, vn_features))\n",
    "        \n",
    "        self.virtual_to_node_mlp = nn.Sequential(nn.Linear(vn_features, hidden_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_features, edge_in_features))\n",
    "\n",
    "\n",
    "    def forward(self, node_features, edge_features, vn_features, super_vn_features, hypergraph):\n",
    "\n",
    "        # Node Update\n",
    "        transformed_edge_features = self.node_mlp1(edge_features)\n",
    "        updated_node_features = torch.matmul(hypergraph.incidence_matrix, transformed_edge_features)\n",
    "\n",
    "        # Edge Update\n",
    "        transformed_node_features = self.edge_mlp2(node_features)\n",
    "        driver_features = torch.matmul(hypergraph.driver_matrix, transformed_node_features)\n",
    "        sink_features = torch.matmul(hypergraph.sink_matrix, transformed_node_features)\n",
    "        updated_edge_features = torch.cat([driver_features, sink_features], dim=1)\n",
    "        updated_edge_features = self.edge_mlp3(updated_edge_features)\n",
    "        \n",
    "        # First Level VN Update\n",
    "        node_to_virtual_features = self.node_to_virtual_mlp(node_features)\n",
    "        updated_vn_features = torch.matmul(hypergraph.vn_matrix, node_to_virtual_features)\n",
    "        updated_vn_features += self.higher_virtual_to_virtual_mlp(super_vn_features)\n",
    "\n",
    "        # Top Level VN Update\n",
    "        virtual_to_higher_virtual_features = self.virtual_to_higher_virtual_mlp(vn_features)\n",
    "        updated_super_vn_features = torch.sum(virtual_to_higher_virtual_features, dim=0)\n",
    "\n",
    "        # VN to node update\n",
    "        virtual_to_node_features = self.virtual_to_node_mlp(vn_features)\n",
    "        propagated_features = torch.matmul(hypergraph.vn_matrix.T, virtual_to_node_features)\n",
    "        updated_node_features += propagated_features\n",
    "\n",
    "        return updated_node_features, updated_edge_features, updated_vn_features, updated_super_vn_features\n",
    "\n",
    "\n",
    "class DEHNN(nn.Module):\n",
    "    def __init__(self, num_layers, node_in_features, edge_in_features, hidden_features=24):\n",
    "        super(DEHNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Create multiple layers for DEHNN\n",
    "        vn_in_features = node_in_features\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(DEHNNLayer(node_in_features, edge_in_features, vn_in_features, hidden_features))\n",
    "            node_in_features, edge_in_features = edge_in_features, node_in_features\n",
    "            edge_in_features *= 2\n",
    "\n",
    "        self.output_layer = nn.Sequential(nn.Linear(edge_in_features, hidden_features),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_features, 1)\n",
    "                                       )\n",
    "\n",
    "    def forward(self, node_features, edge_features, vn_features, super_vn_features, hypergraph):\n",
    "        # Pass through each layer\n",
    "        for layer in self.layers:\n",
    "            node_features, edge_features, vn_features, super_vn_features = layer(node_features, edge_features, vn_features, super_vn_features, hypergraph)\n",
    "        \n",
    "        # Output prediction for nodes\n",
    "        output = self.output_layer(edge_features)\n",
    "        # sm = nn.Softmax(dim=1)\n",
    "        # output = sm(output)\n",
    "        return output[:,0]\n",
    "\n",
    "\n",
    "# Example hypergraph representation class (simplified)\n",
    "class Hypergraph:\n",
    "    def __init__(self, incidence_matrix, driver_matrix, sink_matrix, vn_matrix):\n",
    "        self.incidence_matrix = incidence_matrix\n",
    "        self.driver_matrix = driver_matrix\n",
    "        self.sink_matrix = sink_matrix\n",
    "        self.vn_matrix = vn_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "clean_data_dir = '../../data/chips/clean_data/'\n",
    "\n",
    "n_samples = 13\n",
    "train_idx = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "train_data = []\n",
    "valid_idx = [11]\n",
    "valid_data = []\n",
    "test_idx = [12]\n",
    "test_data = []\n",
    "\n",
    "for i in range(1, n_samples+1):\n",
    "    connectivity = np.load(clean_data_dir + str(i) + '.connectivity.npz')\n",
    "    incidence_matrix = torch.sparse_coo_tensor(torch.tensor(np.array([connectivity['row'], connectivity['col']])), torch.ones(connectivity['dirs'].shape), dtype=torch.float).to(device)\n",
    "\n",
    "    drivers = np.load(clean_data_dir + str(i) + '.drivers.npz')\n",
    "    driver_matrix = torch.sparse_coo_tensor(torch.tensor(np.array([drivers['col'], drivers['row']])), torch.ones(drivers['data'].shape), dtype=torch.float).to(device)\n",
    "\n",
    "    sinks = np.load(clean_data_dir + str(i) + '.sinks.npz')\n",
    "    sink_matrix = torch.sparse_coo_tensor(torch.tensor(np.array([sinks['col'], sinks['row']])), torch.ones(sinks['data'].shape), dtype=torch.float).to(device)\n",
    "\n",
    "    features = np.load(clean_data_dir + str(i) + '.features.npz')\n",
    "    node_features = features['node_features']\n",
    "    edge_features = features['net_features']\n",
    "    wire = features['hpwl']\n",
    "    # congestion = np.argmax(congestion, axis=1)\n",
    "\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float).to(device)\n",
    "    edge_features = torch.tensor(edge_features, dtype=torch.float).to(device)\n",
    "    # congestion = torch.tensor(congestion, dtype=torch.float).to(device)\n",
    "    wire = torch.tensor(wire, dtype=torch.float).to(device)\n",
    "\n",
    "    num_nodes, num_node_features = node_features.shape\n",
    "    num_edges, num_edge_features = edge_features.shape\n",
    "\n",
    "    virtual_nodes = np.load(clean_data_dir + str(i) + '.virtual_nodes.npz')\n",
    "    vn_rows = virtual_nodes['row']\n",
    "    vn_cols = virtual_nodes['col']\n",
    "    vn_matrix = torch.sparse_coo_tensor(torch.tensor(np.array([vn_rows, vn_cols])), torch.ones(len(vn_rows)), dtype=torch.float).to(device)\n",
    "\n",
    "    num_vn = vn_matrix.shape[0]\n",
    "    num_vn_features = num_node_features\n",
    "    vn_features = torch.zeros((num_vn, num_vn_features), dtype=torch.float).to(device)\n",
    "    super_vn_features = torch.zeros(num_vn_features, dtype=torch.float).to(device)\n",
    "\n",
    "    hypergraph = Hypergraph(incidence_matrix, driver_matrix, sink_matrix, vn_matrix)\n",
    "\n",
    "    if i in train_idx:\n",
    "        train_data.append((node_features, edge_features, vn_features, super_vn_features, hypergraph, wire))\n",
    "    elif i in valid_idx:\n",
    "        valid_data.append((node_features, edge_features, vn_features, super_vn_features, hypergraph, wire))\n",
    "    elif i in test_idx:\n",
    "        test_data.append((node_features, edge_features, vn_features, super_vn_features, hypergraph, wire))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000, 15.4346,  0.0000,  ..., 16.8057, 16.4574, 13.6865],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DE-HNN model\n",
    "model = DEHNN(num_layers=4, node_in_features=num_node_features, edge_in_features=num_edge_features, hidden_features=64).to(device)\n",
    "epochs = 100\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Training Loss: 1.8506, Validation Loss: 1.7389\n",
      "Epoch [20/100], Training Loss: 1.6928, Validation Loss: 1.8171\n",
      "Epoch [30/100], Training Loss: 1.6348, Validation Loss: 1.6231\n",
      "Epoch [40/100], Training Loss: 1.8035, Validation Loss: 1.7939\n",
      "Epoch [50/100], Training Loss: 1.6533, Validation Loss: 1.7003\n",
      "Epoch [60/100], Training Loss: 1.6851, Validation Loss: 1.6257\n",
      "Epoch [70/100], Training Loss: 1.7045, Validation Loss: 1.7871\n",
      "Epoch [80/100], Training Loss: 1.7202, Validation Loss: 1.6887\n",
      "Epoch [90/100], Training Loss: 1.6062, Validation Loss: 1.6624\n",
      "Epoch [100/100], Training Loss: 1.6115, Validation Loss: 1.5846\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training Loop (example)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for idx in range(len(train_data)):\n",
    "        node_features, edge_features, vn_features, super_vn_features, hypergraph, congestion = train_data[idx]\n",
    "        # Forward pass\n",
    "\n",
    "        output = model(node_features, edge_features, vn_features, super_vn_features, hypergraph)\n",
    "        # output = output[:,0]\n",
    "        # print(output)\n",
    "        \n",
    "        # Dummy target for illustration (binary labels for each node: 0 for not congested, 1 for congested)\n",
    "        target = congestion\n",
    "        \n",
    "        # print(target)\n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss\n",
    "    if epoch % 10 == 9:\n",
    "        model.eval()\n",
    "        node_features, edge_features, vn_features, super_vn_features, hypergraph, congestion = valid_data[0]\n",
    "        output = model(node_features, edge_features, vn_features, super_vn_features, hypergraph)\n",
    "        target = congestion\n",
    "        valid_loss = criterion(output, target)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {loss.item():.4f}, Validation Loss: {valid_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features, edge_features, vn_features, super_vn_features, hypergraph, congestion = test_data[0]\n",
    "output = model(node_features, edge_features, vn_features, super_vn_features, hypergraph)\n",
    "target = congestion\n",
    "real = target.detach().cpu().numpy()\n",
    "pred = output.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.285402 , 15.144658 , 13.658212 , ..., 15.475734 , 15.011228 ,\n",
       "       15.0821495], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.558969, 12.925888, 13.031361, ..., 15.367368, 14.852118,\n",
       "       15.112644], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4245042"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(real - pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3403206"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((real - pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m real\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "np.mean(pred.argmax(axis=1) == real.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861234492265278"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred == real)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
